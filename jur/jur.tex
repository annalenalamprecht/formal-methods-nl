\documentclass[sigplan,10pt,noacm]{acmart}
\settopmatter{printfolios=false,printccs=false,printacmref=false}

\acmConference{A Research Agenda for Formal Methods in The Netherlands}%
  {September 3--4, 2018}%
  {Lorentz Center, Leiden, The Netherlands}
\acmYear{2018}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

\bibliographystyle{ACM-Reference-Format}

\setcopyright{none}

\begin{document}

\title{The Usability of Static Type Systems}
\author{Jurriaan Hage}

\affiliation{
  \institution{Universiteit Utrecht}
  \country{The Netherlands}
}
\email{j.hage@uu.nl}
\maketitle


\section{Introduction}

Types are used in statically typed languages to guarantee that
``well-typed programs do not go wrong'' (for the right definition of
wrong). Typically, this means that the compiler for the language
prevents certain programs from compiling, because it has discovered
that while running the program a value may be passed to an operation that
works on values of an incompatible type. Such a type system is called an 
intrinsic type system,
as it is part of the language definition that defines what are valid
programs (for the given language). 

Rice's theorem~\cite{ricestheorem} implies that no type system for a Turing complete
language can precisely characterize the set of programs that always go right.
In a statically typed language this means that the type system allows
only a subset of such programs. For example, a compiler for such a language
will enforce type correctness for all parts of a program, even for dead code.

Another example of such over-approximation is the following. 
According to the Hindley-Milner type discipline~\cite{milner78theory} (used as the basis
for the type systems of many statically typed functional languages), 
an expression like $(\lambda x . x x) (\lambda y. y)$ is considered
ill-typed. The reason is that in the first lambda-abstraction $x$ is applied
to itself, leading to an infinite type to be inferred for it, something which
is not allowed within the discipline. For that reason, people have sought
to extend the type system leading to the invention of so-called 
higher-ranked types.

Extending and refining the intrinsic type system of a programming language to 
ensure that it can soundly (with respect to the semantics of the language)
accept more and more programs is a game the programming language community
has been playing for some time. For a language such as Haskell alone, 
type system concepts such as Generalized Abstract Datatypes (GADTs)~\cite{vytiniotis06gadts},
and many of Haskell's other type system extensions 
have been developed to allow the programmer to express more precise correctness
properties for their programs. At the extreme end of that spectrum we find
the dependently typed languages, such as Agda and Idris, in which the worlds of 
type and values have
merged so that almost any property can be expressed within the 
type system~\cite{wouter}.

The development of new type system features to extend the set of known
well-behaved programs has some of the characteristics of an armament race.
Consider the following, highly idealized, scenario for the programming
language X.
At one point, users of X discover that a particular class of 
properties cannot be easily expressed in X, or that 
certain classes of programs that
clearly do not go wrong are forbidden by its type system.
This prompts programming language researchers to develop extensions to or
refinements of the existing type system of X to deal with this issue;
prototype implementations are made to experiment with the new ``weapon'';
interactions with existing features of X are (hopefully) considered and
if everything proceeds as planned, the new feature can be placed into the
hands of the programmer by an implementation into a industry-strength compiler
for X, unaware that some of these new features can easily blow up in 
your face.

\section{The diagnosis of type errors}

Fortunately, most programs and compilers do not actually blow up in anyone's 
face. What a compiler might do, is refuse to compile a program and generate a 
type error
message. And, the more complicated and advanced the type system and its
implementation is, the harder it will be to convey such a message
correctly and comprehrensibly. This is not only due to 
the intricacy of the new concept, but also there seems to be a tendency
to focus only on the implementation of the concept itself. 
Dealing with all the complicated interactions with other features often takes
second place. If the usability of a new feature receives any attention at all
it gets very little, and often as an afterthought.
%(A notable exception is Elm that only includes only concepts that the designers believe they can deal with in a way that it does not hamper the programmer. This, however, has now seemed to lead to  an adversity to introduce new features at all.)

Sometimes, the design
of a new feature is very pleasing from a programming language viewpoint, but
unintuitive from a programmer's viewpoint. A good example is the notion of
type classes in Haskell to model ad-hoc polymorphism (aka overloading, the 
ability to refer to, say, the implementation of equality for strings and for
booleans with the same name). In the setting of Haskell, when 
a programmer accidentally compares two functions, the type error message 
may suggest to add a method for comparing functions, although no sensible
implementation can in fact be given. 
In practice, the programmer simply forgot to provide 
arguments to the functions. In the presence of overloaded numerals such error messages 
can become even more confusing.

Other challenges include the diagnosis of type errors in 
Domain-Specific Languages (DSLs) embedded into a general purpose host 
language~\cite{hudak96building}.
The aim in this case is to introduce a new language specialized for a domain
as part of an existing (host) language. As part of the embedding, we may
even want to use the type system of the host to encode type-like properties
for the embedded language. Type error diagnosis in such a setting is quite
different from ordinary type error diagnosis, in that the host language
compiler has absolutely no knowledge of the domain we are dealing with. In
particular, error messages will typically fail to take in domain 
terms to the programmer. This information then has to be provided as part of 
the DSL definition. Some solutions
to this problem can be found in the literature~\cite{serrano16twostage}, 
and although some
implementations exist in realistic languages, much work still has to be done.

At the farthest extreme in terms of the guarantees that can be provided
by the programmer we find the dependently typed languages (see \cite{wouter}
for more details). In this setting computation and type have all become one.
This means that very precise properties can be checked, although
typically the language itself imposes certain demands on the programs to 
make type checking work. The core idea of this paradigm is that code 
comes with a correctness proof for the code, integrated
seamlessly into a single program. In practice, these languages are very hard to
use, introducing diagnosis problems at various levels: on top of the 
usual unification errors, e.g., a function is called with arguments
in the wrong order, at another level we might want the compiler
to suggest strengthening a lemma to make the proof of a theorem go through. 

\section{Transparent programmer assistance for optimising functional programs}

It may not be at all clear that the problems observed in the previous
section carry over to the optimisation of statically typed functional
languages. But here is how.

The advent of intrinsic type system has led to the development of what
are often called type and effect systems (some call these non-standard
type system, or annotated type systems)~\cite{lucassen88effectsystems}. The idea is to
annotate the intrinsic types
with properties of interest (e.g., strictness information for a lazy
language~\cite{holdermans11makingstricterness-jnl}, usage information~\cite{hage07generic}, 
or control-flow information~\cite{holdermans10higherranked}).
The advantages of this approach are twofold: types provide 
additional structure that we can exploit during the analysis, 
and we can reuse vocabulary and implementation techniques from the world of 
type systems. For example,
let-polymorphism in the Hindley-Milner type system gives rise
to so-called let-polyvariance in type and effect systems. 

We can, however, go one step further. Optimisations are usually performed
deep down inside a compiler on a core language to which
the original program has been desugared. Whether an analysis actually
leads to an optimisation, and how that is affected by how the program
was written is not known to the programmer unless he/she is willing
to spend time inspecting the generated object code. Typically, 
after some profiling, we simply try something, and see how that affects 
the running time and memory consumption.

Unsurprisingly, this ad-hoc approach can be very time consuming, a problem
that becomes more pronounced as the abstraction level of language rises.
Although performance is not often a problem these days, when it is then developing
applications in very high-level languages becomes a risk in itself 
and developers may prefer to resort to lower-level languages instead. 
To counter this development,
what we need is that compilers for such high-level languages are transparent in that the 
information they collect for a given program are made available to programmers 
at a suitably high level of abstraction. One way is to present this information
as type signatures decorated with the analysis information. Going one step
further, these signatures can be supplied by the programmer so that
the compiler can either verify that it can derive that information (showing
that the programmer's expectations are correct), or, if this is not the case,
they can be used by the compiler to generate faster code 
(albeit potentially unsafe, this
is not any different from allowing programmers in Haskell to use
\texttt{seq} to enforce strictness.)

Because we have again a situation in which the compiler needs to communicate
with the programmer, the same problems that have bothered implementors of type systems
for statically typed functional languages show up in another guise,
but also bringing their own set of challenges to the table.

\bibliography{jurbib}

\end{document}
